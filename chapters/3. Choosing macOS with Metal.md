# 3.1 Overview

There has never been a better time to start deep learning on macOS. Apple’s transition to Apple Silicon changed the landscape completely. The M1, M2, and M3 chips integrate CPU, GPU, and Neural Engine into a single architecture that shares **unified memory**. This eliminates the bottleneck of copying tensors back and forth between the processor and the graphics card. When training a model on Metal, the CPU and GPU simply operate on the same memory space, which makes everything faster and more efficient.

A Mac mini with an M1 processor and 64 GB of unified memory costs around one thousand dollars. Matching that performance with an NVIDIA-based workstation would require a far higher investment, not to mention the noise, power draw, and driver maintenance such systems usually demand. For students, researchers, and independent developers, a modern Mac represents a compact and silent deep learning workstation that can handle both experimentation and production code. The Metal Performance Shaders (MPS) backend in PyTorch unlocks GPU acceleration on macOS without any additional drivers or CUDA installation, making it ideal for this book’s examples.

  

# 3.2 Setup on MacOS**

# 3.3 Homebrew and Python

Although macOS comes with a system version of Python, it is best to install and manage your own development tools to avoid dependency conflicts. The Homebrew package manager simplifies this process. Open Terminal and install it using the command provided on the Homebrew website. Homebrew installs under /opt/homebrew on Apple Silicon and manages software without interfering with the system files.

After installing Homebrew, update it and then install Python and Git. You will use Git for version control and to clone example projects from this book’s repository. Installing Python this way gives you the latest version while keeping the system Python intact.  
Installation steps: 

/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

% brew update

% brew --version

Homebrew 4.6.18

% python3 —version

At this point you can run Python scripts directly or through an editor such as Visual Studio Code, Xcode, or PyCharm.

# 3.4 Python and Conda Environment

For serious machine learning work, it is essential to isolate dependencies. You can use Python’s built-in venv module or a Conda environment. Conda is especially convenient because it manages binary packages and avoids many compilation issues when dealing with large frameworks like PyTorch.

Navigate and login (Google account) to:

https://www.anaconda.com/download/success

Download Anaconda for Apple Silicon and install as normal package on macOS.

To create an environment using Conda, type 

conda create -n torch_metal python=3.10

Activate it with conda activate torch_metal. Alternatively, you can use the standard virtual environment:  
python3 -m venv venv followed by source venv/bin/activate.

Once the environment is active, all subsequent installations will remain isolated from the system. This protects your setup when new versions of libraries are released and ensures reproducibility for every project in this book. Keep a simple structure under your home folder, such as ~/torch_to_the_metal/notebooks, ~/torch_to_the_metal/data, and ~/torch_to_the_metal/models. It helps maintain order as you work through multiple examples.

# 3.5 Getting Torch

Installing PyTorch on macOS is now simple. Use the command  

pip install torch torchvision torchaudio

  
The latest PyTorch distributions automatically detect Apple Silicon and enable the Metal backend. To verify this, open a Python shell and run:

  

import torch

print(torch.backends.mps.is_available())

  

If it returns True, the GPU is active. You can then move tensors and models to the Metal device by specifying device = torch.device("mps"). To test this further, run a short script:

  

import torch

x = torch.rand(100, 1, device="mps")

y = 3 * x + 2 + 0.1 * torch.randn(100, 1, device="mps")

model = torch.nn.Linear(1, 1).to("mps")

loss_fn = torch.nn.MSELoss()

opt = torch.optim.SGD(model.parameters(), lr=0.1)

  

for _ in range(200):

    opt.zero_grad()

    pred = model(x)

    loss = loss_fn(pred, y)

    loss.backward()

    opt.step()

  

print(model.weight.item(), model.bias.item())

If the printed weight and bias values are close to 3 and 2, your setup is perfect. The computation ran on Metal, demonstrating that gradient propagation and GPU acceleration are working correctly. You can monitor GPU activity through the Activity Monitor app under the GPU tab.

Keep your environment consistent by exporting a requirements file with 

pip freeze > requirements.txt. 

This lets you restore the exact versions later or on another machine. The combination of macOS, PyTorch, and Metal offers a clean, driver-free workflow for experimenting with neural networks at full speed. From here, every subsequent chapter will build upon this foundation, beginning with the most fundamental concept of all — tensors.
# 6.1 Objective 
Train and Generate Music using RNN. Specifically, I would like to generate flute music and notes to practice myself. The flute music I enjoy is European folk music like Gaelic (Irish, Scott) , German, Slavic tunes.

Here is a compact, end-to-end lab you can run on macOS with PyTorch MPS to learn, train, and generate folk flute melodies. Focus is on ABC notation, because Irish and broader European folk tunes are widely available in ABC, they are monophonic, and perfect for an RNN.

# 6.1 Outline

## 6.1.1 Pick representation
- ABC text, one tune per file or separated by X: headers.
- Keep only monophonic voices and strip chords and guitar tabs.
  Concert flute range is about C4 to C7, comfortable D4 to G6. Later you can filter or transpose to this range.
## 6.1.2 Collect a small starter corpus
- Export a few hundred ABC tunes of Irish, German, and Slavic folk. Prioritize reels, jigs, polkas, waltzes, obereks, kujawiaks, kolomyjkas.
    
- Keep keys common for folk flute: D, G, A minor, E Dorian. Optionally transpose everything to D or G to simplify learning.
    
- Keep only headers you need: X, T, M, L, K plus the note lines. Remove ornaments like {grace}, ~, rolls at first.
    

3. Clean and segment
    

- Ensure each tune ends with a marker like \n\n or a custom <EOS>.
    
- Normalize barlines, repeats, and whitespace.
    
- Optional: drop tunes with extreme note ranges.
    

4. Modeling choice
    

- Start with a character-level GRU or LSTM. It is simple and works well for ABC text.
    
- Later you can move to byte-pair tokenization or bar-aware tokens.
    

5. Train fast on Apple Silicon
    

- Use device = torch.device("mps" if torch.backends.mps.is_available() else "cpu").
    
- Small model first: 2 GRU layers, hidden size 384, dropout 0.2, sequence length 256, batch 64, Adam 3e-3, train for ~5 to 20 epochs.
    

6. Generate
    

- Seed with a short ABC prompt containing headers M, L, K and a starter bar like |: d2 e f g a :|
    
- Use temperature sampling. Try temperature 0.9 and top-k 20.
    

7. Export to practice
    

- Convert generated ABC to MIDI and MusicXML with music21, then open in MuseScore or print. Keep tempo moderate and within flute range.

https://github.com/UkiDLucas/DNN-book/tree/main/code/RNN/music


Notes

- Start with a small corpus to verify the pipeline. When it learns barlines, repeats, and consistent keys, scale up.
    
- Use K:D, K:G, K:Am, K:Edor headers in your prompts to steer style.


Open generated.musicxml in MuseScore to print a playable PDF. If notes drift above G6 or below D4 for long stretches, either transpose or filter those bars in preprocessing.

# Preprocessing tips for better folk output

- Strip ornaments on the first pass: remove ~, trills, grace groups {...}, and tuplets. You can reintroduce them later as tokens.
    
- Normalize repeats: convert :| and |: pairs to explicit AA BB structures during training, then optionally allow the model to output repeats after it stabilizes.
    
- Keep meters per set: train separate models for M:6/8 jigs vs M:4/4 reels to reduce mode mixing early on.
    

# Practice-friendly controls

- Temperature: 0.8 to 1.0 for creativity. Lower gives simpler, more practiceable lines.
    
- Bar-count stop: stop generation after a fixed number of bars, for example 16 or 32, by counting barlines.
    
- Range guard: reject or fix notes outside C4..C7. For flute practice, prefer D4..G6.
    
- Tempo: set Q: = 90 to 110 for learning, export multiple speeds.
    

# Milestones

1. Corpus and cleaner done. You can inspect a handful of normalized ABC files.
    
2. Train tiny GRU. It should reproduce syntax like headers, barlines, and simple stepwise motion.
    
3. Generate 16-bar jigs and reels in D and G. Export to MIDI and MusicXML.
    
4. Add top-k, temperature, and bar-limit controls.
    
5. Improve tokenization: switch to subword tokens that respect ABC symbols and barlines.
    
6. Ornament phase: allow grace notes and cuts as tokens, then fine-tune.
    
7. Style adapters: fine-tune small subsets for German and Slavic folk flavors.
    

# Datasets and licensing

- Make sure tunes you train on allow derivative works. Keep a text file with sources for each ABC file you include.
    
- If you plan to publish samples, include attribution for collections that require it.
    

# Stretch goals

- Add a key-aware pitch mask during sampling to reduce accidentals.
    
- Add bar-level conditioning tokens like [M=6/8], [K=Dmix], [DANCE=polka].
    
- Try a small Transformer later for longer-range structure; keep RNN as the quick baseline.
    

If you want, I can drop a ready folder scaffold with data/, scripts/, and a simple cleaner for ABC ornaments next.

  

ChatGPT can make mistakes. Check important info.




# Repository
https://github.com/UkiDLucas/DNN-book/tree/main/code/RNN/music